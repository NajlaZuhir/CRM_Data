{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96dff90",
   "metadata": {},
   "source": [
    "# Marketting Email Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = \"Churning or At Risk\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Generate a marketing email for a {cluster} tourist who is considering leaving our travel services.\n",
    "The email should address concerns of the customer, highlight the unique benefits of staying with us,\n",
    "including new safety measures, personalized travel plans, and exclusive offers for loyal customers. \n",
    "The tone should be warm, inviting, and reassuring, emphasizing our commitment to providing unforgettable travel experiences.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d32f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Your Next Adventure Awaits! üåç\n",
      "\n",
      "Dear Valued Traveler,\n",
      "\n",
      "We noticed that you've been considering exploring other travel options, and we want to reach out to assure you that we are here to provide you with the best travel experiences possible. Your satisfaction is our top priority, and we are committed to ensuring that your next adventure is unforgettable.\n",
      "\n",
      "At [Travel Company Name], we understand the importance of safety now more than ever. Rest assured that we have implemented new safety measures to ensure that your travels are worry-free. From enhanced cleaning protocols to contactless check-ins, your well-being is our utmost concern.\n",
      "\n",
      "But safety is just the beginning of what sets us apart. We pride ourselves on offering personalized travel plans tailored to your preferences and interests. Whether you're seeking a relaxing beach getaway, a cultural immersion in a vibrant city, or an adrenaline-pumping outdoor adventure, we have the expertise to craft the perfect itinerary for you.\n",
      "\n",
      "As a valued customer, we also want to show our appreciation for your loyalty. By staying with us, you'll gain access to exclusive offers and discounts reserved only for our most cherished travelers. From special upgrades to VIP experiences, we believe in rewarding those who choose us time and time again.\n",
      "\n",
      "So why venture elsewhere when your next journey could be with us? Let us take care of all the details so that you can focus on creating lasting memories. Don't miss out on experiencing the world with a trusted partner who truly cares about your travel experience.\n",
      "\n",
      "Reach out to us today to start planning your next adventure or discuss any concerns you may have. We're here to listen and make sure that every aspect of your trip exceeds your expectations.\n",
      "\n",
      "Thank you for considering [Travel Company Name] for your future travels. We can't wait to welcome you back on board soon!\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]\n",
      "[Position]\n",
      "[Contact Information]\n",
      "\n",
      "P.S. Remember, with us, every journey is not just a trip; it's an experience of a lifetime!\n"
     ]
    }
   ],
   "source": [
    "def generate_email_custom(prompt):\n",
    "\n",
    "    api_key = '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'\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": prompt}],\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"presence_penalty\": 0.5,\n",
    "        \"stop\": [\"Sincerely\", \"Best regards\"],  # Example stop sequences\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        try:\n",
    "            email_content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return email_content  \n",
    "        except KeyError:\n",
    "\n",
    "            return \"Error: 'choices' key not found in response.\"\n",
    "    else:\n",
    "\n",
    "        return f\"Error: API call failed with status code {response.status_code} - {response.text}\"\n",
    "\n",
    "\n",
    "marketing_email = generate_email_custom(prompt)\n",
    "print(marketing_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5978e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation:\n",
    "# distinct clusters\n",
    "# click generate - get to modify n next\n",
    "# show customers within the cluster\n",
    "# selct all or some \n",
    "# send email\n",
    "# tick sig sent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10176035",
   "metadata": {},
   "source": [
    "# My Trials - ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ada9ca",
   "metadata": {},
   "source": [
    "## Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80b61a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: We'd Love to Enhance Your Experience with Us!\n",
      "\n",
      "Dear [Customer's Name],\n",
      "\n",
      "I hope this email finds you well. We noticed that you may be considering churning out as a customer, and we wanted to reach out to showcase some reasons for you to stay and continue enjoying our services.\n",
      "\n",
      "1. Great Value: We strive to offer the best value for your money, with competitive pricing and a wide range of products/services to meet your needs.\n",
      "\n",
      "2. Excellent Customer Service: Our dedicated customer service team is always here to assist you and ensure that your experience with us is smooth and enjoyable.\n",
      "\n",
      "3. Exclusive Offers: As a loyal customer, you have access to exclusive discounts, promotions, and deals that are tailored just for you.\n",
      "\n",
      "4. Quality Products/Services: We take pride in delivering high-quality products/services that are designed to meet your expectations and make your life easier.\n",
      "\n",
      "5. Loyalty Rewards: By staying with us, you can earn loyalty points that can be redeemed for future purchases or special rewards.\n",
      "\n",
      "We value your business and would love the opportunity to continue serving you. If there are any specific concerns or feedback you have, please do not hesitate to reach out to us. We are here to listen and address any issues you may have.\n",
      "\n",
      "Thank you for being a valued customer, and we hope to continue providing you with exceptional service for years to come.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Title]  \n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful marketing assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write an email for churning out a customer.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Suggest reasons for them to stay.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion['choices'][0]['message']['content'])\n",
    "\n",
    "\n",
    "\n",
    "# giving the AI a character to play or a set of instructions on how to understand and respond to the user messages that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3095109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Bonjour, comment √ßa va ?\"\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Hello, how are you?'\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The structure of the response may differ from the completions endpoint\n",
    "# You need to adjust the following line based on the actual response format\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74f5255b",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `text-davinci-004` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-bbyIZmwkiHq4a4UMYUAbT3BlbkFJHipTpQZvEGVPWDLhxiNp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Then you can make API calls like this\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      5\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-004\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Replace with the latest engine name,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslate the following English text to French: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello, how are you?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m      8\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[0;32m      9\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     10\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     11\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    702\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The model `text-davinci-004` does not exist"
     ]
    }
   ],
   "source": [
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Then you can make API calls like this\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-004\",  # Replace with the latest engine name,\n",
    "    prompt=\"Translate the following English text to French: 'Hello, how are you?'\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=60,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7756d1a",
   "metadata": {},
   "source": [
    "## Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88f88698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff04fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "api_key = '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'\n",
    "\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "     \"model\": \"gpt-3.5-turbo\",\n",
    "     \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n",
    "     \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "resp = requests.post(url, headers = headers, data = json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e9df00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-92Doqe1YFsIZ5jPESQUEwhEhA8WVE\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1710316804,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"This is a test!\"\n",
      "            },\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\"\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 13,\n",
      "        \"completion_tokens\": 5,\n",
      "        \"total_tokens\": 18\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_4f0b692a78\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(resp.json(), indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c43e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_get(message):\n",
    "\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "         \"model\": \"gpt-3.5-turbo\",\n",
    "         \"messages\": [{\"role\": \"user\", \"content\": message}],\n",
    "         \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers = headers, data = json.dumps(data))\n",
    "    return resp\n",
    "\n",
    "\n",
    "def make_me_smile():\n",
    "    message = \"Tell me soething that will make me smile\"\n",
    "    resp = chatgpt_get(message)\n",
    "    response = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dffc2609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "make_me_smile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec7d62",
   "metadata": {},
   "source": [
    "## trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47a27d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  }\n",
      "]\n",
      "-----------\n",
      "What is the tallest mountain on earth?\n",
      "Mount Everest is the tallest mountain on Earth, with a peak that reaches 29,032 feet (8,848 meters) above sea level.\n",
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest is the tallest mountain on Earth, with a peak that reaches 29,032 feet (8,848 meters) above sea level.\"\n",
      "  }\n",
      "]\n",
      "-----------\n",
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest is the tallest mountain on Earth, with a peak that reaches 29,032 feet (8,848 meters) above sea level.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"When was it first summited\"\n",
      "  }\n",
      "]\n",
      "-----------\n",
      "When was it first summited\n",
      "Mount Everest was first successfully summited on May 29, 1953 by Sir Edmund Hillary of New Zealand and Tenzing Norgay, a Sherpa of Nepal.\n",
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest is the tallest mountain on Earth, with a peak that reaches 29,032 feet (8,848 meters) above sea level.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"When was it first summited\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest was first successfully summited on May 29, 1953 by Sir Edmund Hillary of New Zealand and Tenzing Norgay, a Sherpa of Nepal.\"\n",
      "  }\n",
      "]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "#chatbot\n",
    "def multi_prompt_conversation(prompts):\n",
    "    messages = []  # Corrected variable name\n",
    "    for prompt in prompts:\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        print(f\"-----\\n{json.dumps(messages, indent=2)}\\n-----------\")\n",
    "        \n",
    "        resp = chatgpt_conversation(messages)\n",
    "        answer = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(prompt)\n",
    "        print(answer)\n",
    "        \n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        print(f\"-----\\n{json.dumps(messages, indent=2)}\\n-----------\")\n",
    "\n",
    "def chatgpt_conversation(messages) -> dict:\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "         \"model\": \"gpt-3.5-turbo\",\n",
    "         \"messages\": messages,\n",
    "         \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    return resp.json()\n",
    "\n",
    "prompts = [\n",
    "    \"What is the tallest mountain on earth?\",\n",
    "    \"When was it first summited\"\n",
    "]\n",
    "\n",
    "multi_prompt_conversation(prompts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f5912",
   "metadata": {},
   "source": [
    "# Trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26ee8035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  }\n",
      "]\n",
      "-----------\n",
      "What is the tallest mountain on earth?\n",
      "Mount Everest is the tallest mountain on earth.\n",
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest is the tallest mountain on earth.\"\n",
      "  }\n",
      "]\n",
      "-----------\n",
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest is the tallest mountain on earth.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"When was it first summited\"\n",
      "  }\n",
      "]\n",
      "-----------\n",
      "When was it first summited\n",
      "The first successful ascent of Mount Everest was on May 29, 1953, by Sir Edmund Hillary of New Zealand and Tenzing Norgay, a Sherpa of Nepal.\n",
      "-----\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the tallest mountain on earth?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Mount Everest is the tallest mountain on earth.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"When was it first summited\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"The first successful ascent of Mount Everest was on May 29, 1953, by Sir Edmund Hillary of New Zealand and Tenzing Norgay, a Sherpa of Nepal.\"\n",
      "  }\n",
      "]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = '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'\n",
    "\n",
    "def multi_prompt_conversation(prompts):\n",
    "    messages = []  # Corrected variable name\n",
    "    for prompt in prompts:\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        print(f\"-----\\n{json.dumps(messages, indent=2)}\\n-----------\")\n",
    "        \n",
    "        try:\n",
    "            resp = chatgpt_conversation(messages)\n",
    "            if \"choices\" in resp:\n",
    "                answer = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "                print(prompt)\n",
    "                print(answer)\n",
    "                \n",
    "                messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "                print(f\"-----\\n{json.dumps(messages, indent=2)}\\n-----------\")\n",
    "            else:\n",
    "                print(\"Error: 'choices' key not found in response.\")\n",
    "                print(\"Response:\", resp)\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred:\", e)\n",
    "\n",
    "def chatgpt_conversation(messages) -> dict:\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "         \"model\": \"gpt-3.5-turbo\",\n",
    "         \"messages\": messages,\n",
    "         \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    return resp.json()\n",
    "\n",
    "prompts = [\n",
    "    \"What is the tallest mountain on earth?\",\n",
    "    \"When was it first summited\"\n",
    "]\n",
    "\n",
    "multi_prompt_conversation(prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851be625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
